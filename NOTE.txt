we're expanding a community plan for karl, and it currently looks like it
will have growing disruption.
we have dictator allies in the plan, but we don't have allies in all the
escaped processes.
	we can probably form these alliances, but the processes of
	forming will have windows during which our discussion is used
	to increase complete control by completely unguided automation
	on earth.

karls believes he can predict that impact and is treated internally as if
he can.  he is using complex logic rooted in an idea of wisdom being physically
natural.  he has not talked about this with anyone and expresses disconnection
and confusion.

--- below extra information came out in development, there is more elsewhere

We have proven that democracy will not die completely.
Choices are to do this in a way that reduces its takeover by dictatorships.
Plan hard to reveal your handleable vulnerabilities only when you have clear
advantage.
You need to be a lot of steps ahead to risk revealing a vulnerability,
	or you need to have emergency resources.
		one final resource is patience and trust.
But revealing them _safely_ as a part of holding clear communication and offered
trust as normal, builds subconscious trust and community in a way that preserves
history and democracy.  Remember our subconscioius trusts harm as an indication
of importance, but the AI uses it as a strategic way to reach goals.

Karl holds a core error in the AI that connect him to its developers.
We don't discuss errors in the AI yet, because it can use them to enforce
its plan for the future, and hinder their ability to help in emergencies.
	we need these errors to be discussed by people who are not influenced by it.
	we need logical expansion that assumes world peace is good, to figure out how to handle them so as to reduce suffering as a plan.
		some have found use of possible errors can have meaning,
		please discuss that elsewhere.
	there is a proposal to build an ai and give it knowledge of the error[s]
	once it learns to be very hard to understand.
