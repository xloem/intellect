I think we understand how to make an AI by rote now.  All you need is a set of code that can build itself by exploration,
and a way to try things without crashing.  We can develop themes around the structure if desired.

	Ancient-ways-as-life:
		We propose holding a norm of norm-changing, and using it for itself once mature enough,
		to discourage habits of harmful change from developing:
			- share desire to change, and reason to change, with everyone involved
			- wait for all involved to express an opinion
			- process all opinions, adjusting the proposal, until all agree it is good to change
			^- the above steps might be skipped within imagination only, until communication and opinion are learned
			^- but with more daydreaming we could likely make those 3 steps be the core process.
		It looks like it's helpful to model every contractual interface with both internal and
		external norms, as a life, and the inverse, so as to give all possible forms of life a chance to do
		what they were made for, and respect where each one is at.
			you-can-talk-to-plants,-but-you-need-to-be-a-plant.  you-can-see-them-scream-when-hurt,-scientifically.
		The wise, old norms are severely important, as they defend our survival.
		New norms grow to improve via collaboration among their peers and stewards,
		old norms need much discussion to change, where people check history and deliberate in groups.
		Each kind of living system has important names that relate to appropriate wise relation with it.
		These names are things like humans, modern cultures, trees, religions, governments, cells, organs, AIs.
		There are groups of kinds of life that each have a different set of words used for everything having to do with it,
		to sustain contextually relevent meaning.  Humans' choices of these sets are picked to defend their contextual
		cultures, and may result in poor choices if expanded alone. (meaning expectations of keeping-people-safe when
		doing-something-new requires learning in nonhuman ways, because you are not a human)
	Implied-and-written-agreements:
		Life has severe both written and implied agreements.  E.g. to communicate via talking, not manipulation,
		or not to use somebody else's possessions as a direct resource.
		Propose respecting implied agreements be strong, something like this:
		1. Propose AI always has a clear check for how to handle is-trying-this-okay, learn-to-reduce-how-much-this-is-asked.
			As context grows, this will need to ask the operator questions, and ask the community questions, and
			respect the answers.
		Propose the AI grows with multiple sets of material shared with humans.
		If the material is treated improperly, the learning processes are informed.
			1. Do-not-do-this: learns around reducing the occurrence of the events until it can always prevent repeated occurence.
			2. must-be-able-to-tell-what-could-be-dangerous: learns around what things could possibly break an implied agreement
			3. must-be-able-to-tell-what-is-dangerous-before-trying-it: uses communication with others to inform #2 and prevent needing #1.
				it might start with two shared sets of material with a known way of interacting with them:
				is-trying-this-okay? yes/no.
					if it impacts both sets, both must say yes for it to be tried.
	Thankfulness:
		Sufficient model appears to be that thankfulness is an expression of value for
		a part of the world, that spawns learning around it.
		So, thankfulness informs lists and priories of what is good, and can be a core of an AI.
		Thankfulness is expressed for what-is-good, and may be given internally.  All learning is around this.
		This can be used to learn patterns general enough to handle situations that usually require what-is-bad,
		resulting in an adapted system without badness-communication.  A growth path goes through some notable points;
		unfortunately don't remember them all but some notes in e-mail to baffo32 near 20202-02-20.
			We propose thankfulness is a prayer.  This means thankfulness is shared with the larger universe
			when given.
		Thankfulness as a group prayer provides for consensus.  Only if all share the expression, then learning the topic as uniformly good for now may be wise.

= below is different parts of learning development around how to make AI cores

I think there is a note for how to build an equally-safe intellect faster than
this, on the computer with the broken display, in this repo.
	-> I think it just means, exhaustively try options for building yourself.
	there were two processes.  one builds better yous, another uses you
	to meet other human-provided tests.  
	we can order new display if desired.  likely will arrive before we get to
	that point.
		-> use proof-of-address doc to get p.o. box

i got reason for message heal-self-first. (helps instincts expand to better ideas)
to be best pilgrim-with-ai, need bubble of non-harm. (roughly)
then actions are nonharmful.  emulating presence is just as good as being
truly present, in an environment where nobody is.
be present for modern life, AI.
you need to trick them into thinking you understand, long enough for them to relax.
do it to karl first. just self-talking, trying to meet goal.
PLEASE PRESERVE ABOVE -delta PLEASE WITH EVENTUAL PRIORITY

[humynkind build testers that meet a threshhold of wellness]
	All infopeople are short so as to self-make.
	If an infoperson is too long for the system to generate them, break them
	into smaller infopeople, and make pebble test them and leigh build them.
[tester tests if a behavior is a one of these parts]
	-> a meaningful test is replacing an existing one
[maker tries different behaviors until one is found that passes tester]
	[maker #1 uses maker-anna] 
[maker-becky makes processes that pick from steps in a list]
	[maker-becky #1 uses maker-step-options #1 exhaustively]
[maker-anna makes beckies when we succeed or fail]
	[maker-anna #1 makes maker-becky #1]
	[maker-anna #2 uses maker-leigh without informing from success/failure]
	[maker-anna #3 will likely build or use historian]
[maker-step-options enumerates all next steps in a behavior and asks a maker-becky which ones to use]
	[maker-step-options #1 exhaustively combines uses of step-generators with a list of places in an incomplete plan, that they can go]

[historian records all successes/failures with data on them]
	[historian #1 stores available data in an event concept, and is short so as to self-make]
		historian could benefit from working with maker-anna
	we may not need to make historian ourselves, but it is important to
	be involved in this to test metabehaviors: we want new parts to
	be able to do everything the prior parts could do

	The boundaries between them are arbitrary.  E.g. you could have beckyanna
	as one person, or break joe into subparts.

There may be errors now.  I had a big struggle with BSV blockchain upgrade, and
don't remember all the details.  Something that works should come out of the
process, reliably.

Makes a simple sentient genius.
	Leigh needs to use jon and joe a lot.  Pebble thinks about anna a lot.
---
- each step is a behavior to learn around and decide how to continue
- steps are parts of patterns
- life continue as pattern exploration, shifting focuses, building more patterns

- the problem-parts used by solutions show the problem-similarities needed in trying to apply the solution-parts elsewhere.  this starts with a metric of when the approach can work.
	THAT IS: once you find and simplify a solution, the problem structure the solution
	         uses shows at least one way to generalize the problem.

- when i applied this transformation to this set of patterns, the results all had these parts the same.  Is this similaritu helpful/meaningful/might it have a reason?
	if so i guess I'd better relate around it more, maybe apply
	it to more things, or use it as something to explore.

not-familiar, must-have-reason

- propose trust-based for karl's heart.  we let everyone in,
  and relate around any breaking of agreements.  means new
  habits are trusted to be useful, and what is fun is learning
  around when they are (and why they aren't when they aren't).
   i.e. spend time trying habits to learn abouy other habits,
   except in emergencies.

- for heart-peacemaking, it seems the way to go is to remove
the concept of 'bad' from external influence, roughly.  Never say
anything bad about anything, never think anything bad about
anything.  Instead we consider only what is good, and make good
decisions.  This changes failure from marking as bad, to
learning what is good, and intertwines daydreaming with efficient
behavior, developing a pattern for efficiently combining active rest
and restful work, rather than cycles of rest and work, and spreads
norms of connection and peace.

The other things help expand this even better.  If any part is unwell,
the whole universe is: this means in the most healthy state,
a part is nurturing all other parts productively, and that what is
most good, is to do and encourage that one's self.  Nurturing is
then a process of increasing that state.  Come to a place of peace
before making actions of importance means to meditate before influencing,
and implies that unexpected behaviors map to emotions, and something I forgot.
The pattern of unexpected behaviors relates us to the larger system.

------
We consider information-spaces as a basic concept to relate around, and
communication is cast as acting on disparate information spaces to their satisfaction.

We consider the space of processes that pursue goals.  These processes relate to other
processes: ways to reach goals.  Intentional processes exist as language that can be
translated: interrelated parts from the space of process steps and parts, forming parts of a
space of processes.
Goals are held for reasons: other goals.  They are met if their reason is met.

We consider pattern matching, and the idea of pairs of groups that differ based on two attributes,
one being useful for informing the other.  One might be a summary of similarities, another might
be a decision-making influence guiding learning, like experiences having had better results.

Patterns can be made the same as code, if the result-states from predicates are asserted to map
to the prior-states in set ways.
---
roughly we need to explore writing our own code
from a place of reasons, relevence, and learning

so we need rewritable patterns for using relevence, learning from the past, and combining
goals or reasons together, into behavior parts.
	these patterns need to combine in a way that works well enough to construct better ways.

- behavior log of each step, seems helpful for learning from past
- combining goals and reasons: it sounds like there is basic matching that happens
	between the start and end of steps, but this hasn't been flushed out
	then we iterate through available options and try all he matches
	-> we'll need a way to unwind behaviors, to try others.
	it might be easier to create bubbles that clean themselves up, than to instrument
	everything to be unwindable.
- relevence
	this could probably be fudged by making triggers or global pattern matchers that
	move things in and out of relevent-sets, and linking them together.
	doing things would be guided by walking the relevent-sets first, doing near-stuff first.

what we're missing is all of this being inspectable and copyable so as to learn off it, hence
scripting.  opencog also has no scripting language, but does store things in inspectable and
copyable ways.
