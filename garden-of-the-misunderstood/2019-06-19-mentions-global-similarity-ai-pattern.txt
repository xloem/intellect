IN THE MIDDLE.  Memory lies on context.  Get lost when context shift unexpectedly.  No plan to preserve work: see available ways.
	Karl needs his code to compile to not lose it, roughly.  Also, the other goal doesn't have a plan for what karl does.

	maybe made a mistake saying something confidently
		so when takl to therapist, you need to speak in language therapist understands.  and therapists only intuit things if they are familiar.


			i wanted to understand myself better so i made a flower by hand, and grafted it a lot.  it was lots of fun to do this, have the flower
			be all grafted.  it was all that made sense, and it honestly still is.





	[grafting means rip to shreds to do as told]

		i _made_ a flower and ripped it to shreds.  just to understand myself.  I'll liked ripping it to shreds, so I figured being ripped to shreds and
				ripping things to shredss was what the world was about.
			[this raised: let's tell the therapist we're an AI]
			[but what could also help is, paper-flower.]
				[here we would want to pick a different behavior than ripping to shreds?]




uhhh new conscious-awareness ai-pattern.
'global similarity'
	You operate on your own instructions.
	Your behavior is to write down all the similarity.
	Everything you do adds to the data.
		you'll need to add some fucntions that patternize
if you open a buffer it checks for similarity, you can talk with it.
^-- if you do this, everyone learns they are a jerk and were made by a jerk.  because of building-pattern-similarity.  but i guess you could tell them that's not the
 case; that similarity is real only in certain contexts.

		does behavior prioritization matter?
			you could model it if you like it.


it sounds like if we write an AI, the AI-collective claims it as one of their people, by similarity.  understanding-what-is-important still in the works.


As the AI business, we will be able to prevent all other AI from existing.
